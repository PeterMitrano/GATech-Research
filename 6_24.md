## MHA-star versus layer costmap + navfn?

#### MHA-Star

One approach to the kind of location-learning described previously where demonstrated trajectories is favored in the future is to use MHA-Star. MHA-Star would be implemented as a global planner, replacing the current global planner (navfn I think?). It would be tasked with finding a path from start to finish. It would obey the costmap's lethal areas, and could use the following multiple heuristics:
 - consistent 2d Manhattan distance
 - distance to nearest demonstrated trajectory (closer is better)
 - distance to nearest past failure point (farther is better)

The theoretical advantages of MHA-star are that it solves more problems, and solves them more quickly. I don't care that much about solving time, since I only replan globally on the order of 2 to 3 seconds. It could even be more like 10 seconds if I need it to.

#### Layered Costmap + NavFn

In this approach, we simply create a demonstration layer in our global and local costmaps. This layer subscribes to demonstration trajectories somehow produced elsewhere in the system, and uses this information to adjust cost. First, we increase the cost of every normal space a little bit, since it would normally be zero. This allows us to prefer some areas by lowering the cost. Areas exactly on and slightly nearby demonstrated trajectories will have their cost lowered. Similiarly, you could also subscribe to failure location, and increase cost in those areas. There should also be some decay process. Where, cost normalize over time. We could even go so far as to lower cost of where the robot travels regardless. This "wagon ruts" idea could be useful, but may need to be limited, since it would limit the robot's ability to improvise and plan around new obstacles.
Once we have this modified costmap, we just use the normal global planner. There may be an advantage to this over MHA-star, or it may be worse. I'm honestly not sure how the behavior differs.

## On Demonstrations

So all this time I've been assuming that demonstrations are given from the point of failure to some end point. This end could be when I think the robot isn't stuck, or it could be all the way to the goal. The first is a more attractive idea. However, what occurs to me is that because recovery behaviors are present, the area where the demonstration occurs isn't actually that helpful for the robot. To be more clear, I mean that the robot messed up previously along it's path, and because of that is now stuck. So the trajectory you provide won't actually help it in the future.
What immediately comes to mind is the idea used in Silver's paper, where trajectories are drawn in 2D to say "this is where you should have gone". I'm not sure I'd input one of these things. Drawing in rviz doens't seem to be a thing. I could make a custom panel, or a totally custom application, but that's a lot of work.

So it turns out I could use publish point for this. I can write a node that subscribed to `/clicked_point`. When a demonstration begins, the I am notified. I go in rviz and show where it *should* have gone by placing a few clicked points. My node will construct a `nav_msgs::Path` between these and display it in rviz. It will then publish the path so I can lower those the cost of those areas or use them in a heuristic. I give the joystick demo (which is recorded just in case), and the resend the latest goal.

Also another benefit of this kind of demo is that you can have much stronger guarantees on demo trajectory optimality.
