## More brainstorming (6/1/16)

So I finished reading the Survey of LfD, and a bunch of things seem like they will be applicable.

 - We are using "teleoperation" as our demonstration approach, so our embodiment and record mapping at the Identify mapping
 - We can eliminate issues of the demonstrator working with more data than the robot because the robot is teleoperated using the robots camera and sensors
 - It's possible to demonstrate only with states, and no actions. Specifically, the demonstration could be the path out which is to be executed by a planner, rather than the actions the planners take. This won't work in every case though, because most of the "intervention" cases are caused by the planner failing.
 - If we learn on a per-domain basis (ie. One hospital, or one hotel) we don't have many training examples to work with
 - For reward functions, one option is to use teleoperation to show the robot the reward states and thus eliminate long periods of initial exploration that acquire no reward feedback
 - Since a human operator is fully engaged during the demonstration, and may be a domain expert, we could ask them to annotate or provide feedback. This could mean annotating what he is doing, what the issue is. It could also mean criticizing previous attempts at recovery.
 - We only acquire new demonstration when a failure occurs, at which point the intervention occurs
 - Demonstrations may be suboptimal because human teleoperation is difficult, and messy. We may want to employ smoothing or removal of unnecessary actions to the demonstrations.
 - Since we have few demonstrations, we should consider developing a policy from LfD, but letting that policy evolve with RL.

#### Picking a domain we can demo

Aspects are important when picking a domain:

 - Does it introduce unecessarily difficult problems?
   - Plz no grasping or manipulation
 - Does it mirror the real world problems accurately?
 - Is it portable to other mobile robots?

Real world examples we're considering:

 - Saviok
 - Aethon
 - Fetch Robotics (might they have interventions?)

A demo we can actually do here:

 - Environment is the whole second floor. It's task is to deliver items (like cookies) too and from various desks
 - We give it a static map of the general layout
 - If failure occurs my phone will alert me and I have to teleop it out
 - The path I take out is the demonstration, and features about the failure mode are associated with my demonstration
 - Learning happens
 - As learning occurs, I can provide feedback or annotate failed recovery behaviors as I perform the new demonstration
 - Profit
